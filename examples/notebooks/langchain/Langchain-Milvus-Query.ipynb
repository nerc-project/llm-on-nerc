{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165a3407",
   "metadata": {},
   "source": [
    "## Querying a Milvus index\n",
    "\n",
    "Simple example on how to query content from a Milvus Vector Store.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- A **Milvus** vector database, set up according to [these instructions](../../../vector-databases/milvus/README.md).\n",
    "\n",
    "- Connection credentials to Milvus must be available as environment variables:\n",
    "\n",
    "  - `MILVUS_USERNAME`\n",
    "\n",
    "  - `MILVUS_PASSWORD`\n",
    "\n",
    "- Update the **MILVUS_HOST**, **MILVUS_PORT**, and **MILVUS_COLLECTION** in this notebook to match your deployment settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac3132-6929-4477-9585-31761d7d9848",
   "metadata": {},
   "source": [
    "### Needed packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed97389-9c5b-46a8-bedf-f28bf7038a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q einops==0.7.0 langchain==0.1.9 pymilvus==2.3.6 sentence-transformers==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e11d23-c0ad-4875-b67f-149fc8b14725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8ecae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Base parameters, the Milvus connection info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9376e567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace values according to your Milvus deployment\n",
    "MILVUS_HOST = \"milvus-service\"\n",
    "# MILVUS_HOST = \"milvus-service.<your-namespace>.svc.cluster.local\"\n",
    "MILVUS_PORT = 19530\n",
    "MILVUS_USERNAME = os.getenv('MILVUS_USERNAME')\n",
    "MILVUS_PASSWORD = os.getenv('MILVUS_PASSWORD')\n",
    "MILVUS_COLLECTION = \"demo_collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d51868",
   "metadata": {},
   "source": [
    "### Initialize the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "2025-05-31 03:00:38.482764: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-31 03:00:39.402981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/app-root/lib64/python3.9/site-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "# If you want to use a GPU, you can add the 'device': 'cuda' argument and provided you have used GPU Accelerator on your Workbench.\n",
    "# model_kwargs = {'device': 'cuda'}\n",
    "model_kwargs = {}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_kwargs=model_kwargs,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT, \"user\": MILVUS_USERNAME, \"password\": MILVUS_PASSWORD},\n",
    "    collection_name=MILVUS_COLLECTION,\n",
    "    metadata_field=\"metadata\",\n",
    "    text_field=\"page_content\",\n",
    "    drop_old=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856851c",
   "metadata": {},
   "source": [
    "### Make a query to the index to verify sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9621e231-3541-40bc-85ef-8aa3b2ba2331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f31d28eb45f4f07be7c121c35a2d6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/openshift_ai_tutorial_-_fraud_detection_example/index\n",
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/working_on_data_science_projects/index\n",
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/working_on_data_science_projects/index\n",
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index\n"
     ]
    }
   ],
   "source": [
    "query=\"How can I create a Data Science Project?\"\n",
    "results = store.similarity_search_with_score(query, k=4, return_metadata=True)\n",
    "for result in results:\n",
    "    print(result[0].metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1005e2c",
   "metadata": {},
   "source": [
    "### Work with a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ce0caa-a514-4a4d-985b-7e5ac89356ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dede8e3-f185-4aae-a5f1-6c67876f0f65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11651c4c28e4787be95dd96e75c6a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='.\\nProcedure\\n1\\n. \\nOn the navigation menu, select \\nData science projects\\n. This page lists any existing projects that\\nyou have access to. From this page, you can select an existing project (if any) or create a new\\none.\\nNOTE\\nCHAPTER 2. SETTING UP A PROJECT AND STORAGE\\n5', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/openshift_ai_tutorial_-_fraud_detection_example/index', 'page': 8}),\n",
       " Document(page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\nTable of Contents\\nPREFACE\\nCHAPTER 1. USING DATA SCIENCE PROJECTS\\n1.1. CREATING A DATA SCIENCE PROJECT\\n1.2. UPDATING A DATA SCIENCE PROJECT\\n1.3. DELETING A DATA SCIENCE PROJECT\\nCHAPTER 2. USING PROJECT WORKBENCHES\\n2.1. CREATING A WORKBENCH AND SELECTING AN IDE\\n2.1.1. About workbench images\\n2.1.2. Creating a workbench\\n2.2. STARTING A WORKBENCH\\n2.3. UPDATING A PROJECT WORKBENCH\\n2.4. DELETING A WORKBENCH FROM A DATA SCIENCE PROJECT\\nCHAPTER 3. USING CONNECTIONS', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/working_on_data_science_projects/index', 'page': 4}),\n",
       " Document(page_content='CHAPTER 1. USING DATA SCIENCE PROJECTS\\n1.1. CREATING A DATA SCIENCE PROJECT\\nTo implement a data science workflow, you must create a project. In OpenShift, a project is a Kubernetes\\nnamespace with additional annotations, and is the main way that you can manage user access to\\nresources. A project organizes your data science work in one place and also allows you to collaborate\\nwith other developers and data scientists in your organization.\\nWithin a project, you can add the following functionality:\\nConnections so that you can access data without having to hardcode information like endpoints\\nor credentials.\\nWorkbenches for working with and processing data, and for developing models.\\nDeployed models so that you can test them and then integrate them into intelligent\\napplications. Deploying a model makes it available as a service that you can access by using an\\nAPI.\\nPipelines for automating your ML workflow.\\nPrerequisites\\nYou have logged in to Red Hat OpenShift AI.', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/working_on_data_science_projects/index', 'page': 7}),\n",
       " Document(page_content='CHAPTER 3. CREATING A DATA SCIENCE PROJECT\\nTo implement a data science workflow, you must create a project. In OpenShift, a project is a Kubernetes\\nnamespace with additional annotations, and is the main way that you can manage user access to\\nresources. A project organizes your data science work in one place and also allows you to collaborate\\nwith other developers and data scientists in your organization.\\nWithin a project, you can add the following functionality:\\nConnections so that you can access data without having to hardcode information like endpoints\\nor credentials.\\nWorkbenches for working with and processing data, and for developing models.\\nDeployed models so that you can test them and then integrate them into intelligent\\napplications. Deploying a model makes it available as a service that you can access by using an\\nAPI.\\nPipelines for automating your ML workflow.\\nPrerequisites\\nYou have logged in to Red Hat OpenShift AI.', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.20/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index', 'page': 10})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
